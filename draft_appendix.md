## Acknowledgements

We would like to thank Douglas Eck, Geoffrey Hinton, Anja Austermann, Jeff Dean, Luke Metz, Ben Poole, Jean-Baptiste Mouret, Michiel Adriaan Unico Bacchiani, Heiga Zen, and Alexander M. Lamb for their thoughtful feedback.

The experiments in this work were performed on virtual machines provided by [Google Cloud Platform](https://cloud.google.com/).

This article was prepared using the [Distill](https://distill.pub) [template](https://github.com/distillpub/template). Interactive demos were built with [p5.js](https://p5js.org).

Any errors here are our own and do not reflect opinions of our proofreaders and colleagues. If you see mistakes or want to suggest changes, feel free to contribute feedback by participating in the discussion [forum](https://github.com/attentionneuron/attentionneuron.github.io/issues) for this article.

<h3 id="citation">Citation</h3>

For attribution in academic contexts, please cite this work as

<pre class="citation short">Yujin Tang and David Ha, "The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning", 2021.</pre>

BibTeX citation

<pre class="citation long">@article{attentionneuron2021,
  author = {Yujin Tang and David Ha},
  title  = {The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning},
  eprint = {arXiv:21XX.XXXXX},
  url    = {https://attentionneuron.github.io},
  note   = "\url{https://attentionneuron.github.io}",
  year   = {2021}
}</pre>

## Open Source Code

We will provide a reference implementation to replicate results of this work soon.

## Reuse

Diagrams and text are licensed under Creative Commons Attribution [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/) with the [source available on GitHub](https://github.com/attentionneuron/attentionneuron.github.io), unless noted otherwise. The figures that have been reused from other sources donâ€™t fall under this license and can be recognized by the citations in their caption.

## Supplementary Materials

For further discussion about the implementation details of the experiments, and results for multiple independent runs of the search algorithms, please refer to the Appendix section in the [pdf](https://arxiv.org/abs/21XX.XXXXX) version of this article.
